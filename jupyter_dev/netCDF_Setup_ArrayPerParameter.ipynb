{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f229ab",
   "metadata": {},
   "source": [
    "**netCDF Setup Utility**\n",
    "\n",
    "Use this notebook to set up empty netCDF files to be loaded onto each vessel. Currently, this setup utility only supports the use of two vessels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea733e9",
   "metadata": {},
   "source": [
    "In the cell below, please enter the required input files and runtime parameters or leave them as their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff41fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey area polygon file\n",
    "survey_area_file = 'surveyAreas/yoho_polygon.poly'\n",
    "\n",
    "# Output netCDF files for each vessel\n",
    "vesselA_output_file = 'output/vA_model_yoho.nc'\n",
    "vesselB_output_file = 'output/vB_model_yoho.nc'\n",
    "\n",
    "# Geodetic Parameters\n",
    "input_geodetics = 'EPSG:4326'\n",
    "project_geodetics = 'EPSG:32619'\n",
    "\n",
    "# Vessel names, types, and equipment\n",
    "vesselA_name = 'Kelp King'\n",
    "vesselA_make = 'OSP Vessel'\n",
    "vesselA_GNSS_type = 'single_code'\n",
    "vesselA_sonar_type = 'singlebeam'\n",
    "\n",
    "vesselB_name = 'Deux Banane'\n",
    "vesselB_make = 'Seafloor Hydrone'\n",
    "vesselB_GNSS_type = 'single_multi'\n",
    "vesselB_sonar_type = 'singlebeam'\n",
    "\n",
    "# Survey total propagated uncertainty parameters in meters\n",
    "allowable_sigmaVertical = 0.15\n",
    "\n",
    "vesselA_sigmaVertical = 0.1\n",
    "vesselA_sigmaHorizontal = 0.2\n",
    "\n",
    "vesselB_sigmaVertical = 0.5\n",
    "vesselB_sigmaHorizontal = 1.5\n",
    "\n",
    "# Safe area parameters in meters\n",
    "vesselA_min_safe_depth = 2\n",
    "vesselB_min_safe_depth = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a3757",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65c95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from shapely.geometry import Point, box\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely.ops import transform\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "from shapely.prepared import prep\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import xarray as xr \n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e60cf",
   "metadata": {},
   "source": [
    "Set up the geodetic transformation to be used to transform from latitude and longitude to northings and eastings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb776f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84 = pyproj.CRS(input_geodetics)\n",
    "utm = pyproj.CRS(project_geodetics)\n",
    "\n",
    "projection = pyproj.Transformer.from_crs(wgs84, utm, always_xy=True).transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e83ec",
   "metadata": {},
   "source": [
    "Import survey area, transform to UTM, find the home point and bounding box of the survey area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b16951",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_area_poly_list = []\n",
    "\n",
    "# Extract the points from the .poly file.\n",
    "with open(survey_area_file, 'r') as csv_file:\n",
    "    next(csv_file)\n",
    "    reader = csv.reader(csv_file, delimiter=' ')\n",
    "    for row in reader:\n",
    "        survey_area_poly_list.append([float(row[1]), float(row[0])])\n",
    "\n",
    "# Create shapely polygon from survey boundary\n",
    "survey_area_poly_input = Polygon(survey_area_poly_list)\n",
    "\n",
    "# Reproject from WGS84 to UTM\n",
    "survey_area_poly_project = transform(projection, survey_area_poly_input)\n",
    "\n",
    "# Extract the northing and easting points from the reprojected polygon and get rounded values into pandas dataframe\n",
    "survey_area_easts_array, survey_area_norths_array = survey_area_poly_project.exterior.coords.xy\n",
    "survey_area_easts = list(survey_area_easts_array)\n",
    "survey_area_norths = list(survey_area_norths_array)\n",
    "survey_area_bounds = pd.DataFrame({'x': survey_area_easts, 'y': survey_area_norths})\n",
    "survey_area_bounds['x_r'] = survey_area_bounds['x'].round()\n",
    "survey_area_bounds['y_r'] = survey_area_bounds['y'].round()\n",
    "\n",
    "# Find the home point for the survey area for indexing purposes and the away point to define maximum extent and the ranges\n",
    "home = (int(survey_area_bounds.x_r.min()), int(survey_area_bounds.y_r.min())) # east, north\n",
    "away = (int(survey_area_bounds.x_r.max() - home[0]), int(survey_area_bounds.y_r.max() - home[1])) # east, north\n",
    "east_range = range(0, away[1], 1)\n",
    "north_range = range(0, away[0], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bace13",
   "metadata": {},
   "source": [
    "Create empty numpy arrays, then put them in data arrays, and put those in a dataset. Also assign metadata values. \n",
    "\n",
    "Initially for each vessel there will be only one depth hypothesis layer, a soundings layer, an uncertainty layer, and an M2 layer, along with a safe/not safe layer. Additional layers will be added, starting with a second depth hypothesis layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20128ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up empty numpy arrays then fill with NaNs\n",
    "empty_depth = np.empty((away[1], away[0], 5))\n",
    "empty_soundings = np.empty((away[1], away[0], 5))\n",
    "empty_M2 = np.empty((away[1], away[0], 5))\n",
    "empty_stdev = np.empty((away[1], away[0], 5))\n",
    "empty_safe = np.empty((away[1], away[0], 5))\n",
    "\n",
    "empty_depth[:] = np.nan\n",
    "empty_soundings[:] = np.nan\n",
    "empty_M2[:] = np.nan\n",
    "empty_stdev[:] = np.nan\n",
    "empty_safe[:] = np.nan\n",
    "\n",
    "\n",
    "# Put the empty arrays into xarray dataArrays\n",
    "vT_depth = xr.DataArray(empty_depth, \n",
    "                        dims=('north', 'east', 'vessel'), \n",
    "                        coords=[east_range, north_range, ['A', 'B', 'C', 'D', 'E']])\n",
    "vT_soundings = xr.DataArray(empty_soundings, \n",
    "                            dims=('north', 'east', 'vessel'), \n",
    "                            coords=[east_range, north_range, ['A', 'B', 'C', 'D', 'E']])\n",
    "vT_M2 = xr.DataArray(empty_M2, \n",
    "                     dims=('north', 'east', 'vessel'), \n",
    "                     coords=[east_range, north_range, ['A', 'B', 'C', 'D', 'E']])\n",
    "vT_stdev = xr.DataArray(empty_stdev, \n",
    "                        dims=('north', 'east', 'vessel'), \n",
    "                        coords=[east_range, north_range, ['A', 'B', 'C', 'D', 'E']])\n",
    "vT_safe = xr.DataArray(empty_safe, \n",
    "                       dims=('north', 'east', 'vessel'), \n",
    "                       coords=[east_range, north_range, ['A', 'B', 'C', 'D', 'E']])\n",
    "\n",
    "\n",
    "# Create a Dataset to serve as a template, then save a copy for each vessel\n",
    "vT = xr.Dataset(dict(depth=vT_depth, soundings=vT_soundings, M2=vT_M2, stdev=vT_stdev, safe=vT_safe))\n",
    "\n",
    "vT.attrs['depth_units'] = 'meters'\n",
    "vT.attrs['uncertainty_units'] = 'meters'\n",
    "vT.attrs['allowable_sigmaVertical'] = allowable_sigmaVertical\n",
    "vT.attrs['home_point'] = home\n",
    "vT.attrs['away_point'] = away\n",
    "\n",
    "vT.attrs['vesselA_name'] = vesselA_name\n",
    "vT.attrs['vesselA_make'] = vesselA_make\n",
    "vT.attrs['vesselA_GNSS_type'] = vesselA_GNSS_type\n",
    "vT.attrs['vesselA_sonar_type'] = vesselA_sonar_type\n",
    "vT.attrs['vesselA_sigmaVertical'] = vesselA_sigmaVertical\n",
    "vT.attrs['vesselA_sigmaHorizontal'] = vesselA_sigmaHorizontal\n",
    "vT.attrs['vesselA_min_safe_depth'] = vesselA_min_safe_depth\n",
    "\n",
    "vT.attrs['vesselB_vessel_name'] = vesselB_name\n",
    "vT.attrs['vesselB_vessel_make'] = vesselB_make\n",
    "vT.attrs['vesselB_vessel_GNSS_type'] = vesselB_GNSS_type\n",
    "vT.attrs['vesselB_vessel_sonar_type'] = vesselB_sonar_type\n",
    "vT.attrs['vesselB_sigmaVertical'] = vesselB_sigmaVertical\n",
    "vT.attrs['vesselB_sigmaHorizontal'] = vesselB_sigmaHorizontal\n",
    "vT.attrs['vesselB_min_safe_depth'] = vesselB_min_safe_depth\n",
    "\n",
    "vT.to_netcdf(path=vesselA_output_file)\n",
    "vT.to_netcdf(path=vesselB_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4be3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(chr, range(65, 91)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bc021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
